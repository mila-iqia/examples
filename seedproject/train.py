import os

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

PATH = "./cifar_net.pth"

transform = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]
)


def option(path, default=None, vtype=str):
    """Fetch a configurable value in the environment"""

    path = path.replace(".", "_").upper()
    full = f"SEEDPROJECT_{path}"
    value = vtype(os.environ.get(full, default))
    return value


class Net(nn.Module):
    """My Module"""

    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        """Forward pass"""
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)  # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


def train(args):
    """Train function"""
    trainset = torchvision.datasets.CIFAR10(
        root=option("dataset.dest", "/tmp/datasets/cifar10"),
        train=True,
        download=True,
        transform=transform,
    )

    trainloader = torch.utils.data.DataLoader(
        trainset,
        batch_size=2048,
        shuffle=True,
        num_workers=2,
    )

    device = torch.device("cuda")
    net = Net().to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(
        net.parameters(),
        lr=args.lr,
        momentum=args.momentum,
        weight_decay=args.weight_decay,
    )

    losses = []

    for epoch in range(args.epochs):  # loop over the dataset multiple times

        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward + backward + optimize
            outputs = net(inputs.to(device))
            loss = criterion(outputs, labels.to(device))
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if i % 10 == 0:  # print every 2000 mini-batches
                print(f"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}")
                running_loss = 0.0

            losses.append(loss.detach())

        loss = sum([l.item() for l in losses]) / len(losses)

    print("Finished Training")

    try:
        from orion.client import report_objective

        report_objective(loss, name="loss")
    except ImportError:
        print("Orion is not installed")


def main():
    """Main function"""

    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--epochs", type=int, default=10)
    parser.add_argument("--lr", type=float, default=0.01)
    parser.add_argument("--weight_decay", type=float, default=0.001)
    parser.add_argument("--momentum", type=float, default=0.9)
    parser.add_argument("--config", type=str, default=None, help="")
    args = parser.parse_args()

    if args.config is not None:
        import json

        with open(args.config, "r") as file:
            config = json.load(file)

        args = vars(args)
        args.update(config)
        args.pop("config")
        args = argparse.Namespace(**args)
        print(args)

    train(args)


if __name__ == "__main__":
    main()
